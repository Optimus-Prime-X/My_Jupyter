{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Optimus-Prime/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/Optimus-Prime/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir1 = '/Users/Optimus-Prime/Desktop/homework/dset1/train'\n",
    "datadir2 = '/Users/Optimus-Prime/Desktop/homework/dset2/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epoch = 30000             \n",
    "batch_size = 300\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 224*224*3\n",
    "n_classes = 65\n",
    "dropout = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,128,128,3])\n",
    "y = tf.placeholder(tf.int32,[None,n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reading(datadir,nameinput):\n",
    "    classes = os.listdir(datadir)\n",
    "    classes.remove('.DS_Store')\n",
    "\n",
    "    img_path_total = []\n",
    "    img_label_total = []\n",
    "    for name in classes:\n",
    "        class_path = datadir + '/'+name + '/'\n",
    "        index = int(name[5:])\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path_total.append(class_path + img_name)  # 每张图片的地址\n",
    "            img_label_total.append(index) #每张图片的标签\n",
    "    img_total = [[img_label_total[i],img_path_total[i]] for i in range(len(img_label_total))]\n",
    "    #print(img_total)\n",
    "    rd.shuffle(img_total)\n",
    "    #print(img_total)\n",
    "    y_label, x_path = [img_total[i][0] for i in range(len(img_label_total))],[img_total[i][1] for i in range(len(img_label_total))]\n",
    "    \n",
    "    #for i in range(len(img_total)):\n",
    "    x_train_path, x_test_path, y_train, y_test = train_test_split(x_path, y_label, test_size = 0.2)  \n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(nameinput+'_train'\".tfrecords\")  # 要生成的文件\n",
    "    for i in range(len(y_train)):\n",
    "            img = Image.open(x_train_path[i])\n",
    "            img = img.resize((224, 224))\n",
    "            img_raw = img.tobytes()  # 将图片转化为二进制格式\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[y_train[i]])),\n",
    "                'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n",
    "            }))  # example对象对label和image数据进行封装\n",
    "            writer.write(example.SerializeToString())  # 序列化为字符串\n",
    "    writer.close()\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(nameinput+'_test'\".tfrecords\")  # 要生成的文件\n",
    "    for i in range(len(y_test)):\n",
    "            img = Image.open(x_test_path[i])\n",
    "            img = img.resize((224, 224))\n",
    "            img_raw = img.tobytes()  # 将图片转化为二进制格式\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[y_test[i]])),\n",
    "                'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n",
    "            }))  # example对象对label和image数据进行封装\n",
    "            writer.write(example.SerializeToString())  # 序列化为字符串\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reading(datadir1,'data1')\n",
    "Reading(datadir2,'data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(filename): # 读入dog_train.tfrecords\n",
    "    filename_queue = tf.train.string_input_producer([filename],num_epochs=30)#生成一个queue队列\n",
    " \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)#返回文件名和文件\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                       })#将image数据和label取出来\n",
    " \n",
    "    img = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "    img = tf.reshape(img, [224, 224, 3])  #reshape为128*128的3通道图片\n",
    "    img = tf.cast(img, tf.float32) * (1. / 255) - 0.5 #在流中抛出img张量\n",
    "    label = tf.cast(features['label'], tf.int32) #在流中抛出label张量\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_train,label1_train = read_and_decode('./data1_train.tfrecords')\n",
    "image2_train,label2_train = read_and_decode('./data2_train.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage1_train, label1_train = g_batches(\"./data1_train.tfrecords\",30)\\nwith tf.Session() as sess:\\n    init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\\n    sess.run(init)\\n    coord = tf.train.Coordinator()\\n    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\\n    for i in range(10):\\n        label1_train_ = sess.run(label1_train)\\n        print(label1_train_)\\n    coord.request_stop()\\n    coord.join(threads)\\nsess.close()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "image1_train, label1_train = g_batches(\"./data1_train.tfrecords\",30)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    for i in range(10):\n",
    "        label1_train_ = sess.run(label1_train)\n",
    "        print(label1_train_)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "sess.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_batches(filename,batchsize):\n",
    "    img, label = read_and_decode(filename)\n",
    "    min_after_dequeue = 100\n",
    "    capacity = min_after_dequeue + 3*batchsize\n",
    "    \n",
    "    img_batch, label_batch = tf.train.shuffle_batch([img, label],\n",
    "                                                   batch_size = batchsize,\n",
    "                                                   capacity = capacity,\n",
    "                                                   min_after_dequeue = min_after_dequeue)\n",
    "    return img_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#卷积操作\n",
    "def conv2d(name, x, W, b,strides = 1):\n",
    "    x = tf.nn.conv2d(x, W, strides = [1,strides,strides,1], padding = 'SAME')\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x,name = name)\n",
    "#定义pooling\n",
    "def maxpool2d(name, x, k=2):\n",
    "    return tf.nn.max_pool(x,ksize = [1,k,k,1],strides=[1,k,k,1],padding = 'SAME',name = name)\n",
    "#BN\n",
    "def B_Norm(name, l_input , lsize = 4):\n",
    "    return tf.nn.lrn(l_input, lsize, bias = 1.0, alpha = 0.001/9, beta = 0.75, name = name)\n",
    "\n",
    "#网络参数\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([11,11,3,48])),#224*224*3 ---> 16*16*48 (pooling : /2 ; stride = 4)\n",
    "    'wc2': tf.Variable(tf.random_normal([5,5,48,48])), #16*16*48 ---> 8*8*48\n",
    "    'wc3': tf.Variable(tf.random_normal([3,3,48,48])), #8*8*48 ---> 4*4*48\n",
    "    'wf1': tf.Variable(tf.random_normal([768,256])), #768*256 ---> 256*n_classes\n",
    "  # 'wf2': tf.Variable(tf.random_normal([1024,1024])),\n",
    "    'out': tf.Variable(tf.random_normal([256,n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([48])),\n",
    "    'bc2': tf.Variable(tf.random_normal([48])),\n",
    "    'bc3': tf.Variable(tf.random_normal([48])),\n",
    "    'bf1': tf.Variable(tf.random_normal([256])),\n",
    "   #'bf2': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    #全连接层2\\n    fc2 = tf.reshape(fc1, [-1,weights['wf2'].get_shape().as_list()[0]])\\n    fc2 = tf.add(tf.matmul(fc2,weights['wf2']),biases['bf2'])\\n    fc2 = tf.nn.relu(fc2)\\n    #dropout\\n    fc2 = tf.nn.dropout(fc2,dropout)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cnn_net(x,weights,biases,dropout):\n",
    "    x = tf.reshape(x, shape = [-1,128,128,3])\n",
    "    #第一层\n",
    "    conv1 = conv2d('conv1', x, weights['wc1'], biases['bc1'],strides = 4)\n",
    "    pool1 = maxpool2d('pool1', conv1, k = 2)\n",
    "    B_Norm1 = B_Norm('BN1', pool1, lsize = 4)\n",
    "    #第二层\n",
    "    conv2 = conv2d('conv2',B_Norm1,weights['wc2'], biases['bc2'])\n",
    "    pool2 = maxpool2d('pool2',conv2, k = 2)\n",
    "    B_Norm2 = B_Norm('BN2', pool2, lsize = 4)\n",
    "    #第三层\n",
    "    conv3 = conv2d('conv3',B_Norm2, weights['wc3'], biases['bc3'])\n",
    "    pool3 = maxpool2d('pool3',conv3, k = 2)\n",
    "    B_Norm3 = B_Norm('BN3', pool3, lsize = 4)\n",
    "    \n",
    "    #全连接层1\n",
    "    fc1 = tf.reshape(B_Norm3, [-1,weights['wf1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1,weights['wf1']),biases['bf1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    #dropout\n",
    "    fc1 = tf.nn.dropout(fc1,dropout)\n",
    "    \n",
    "    \n",
    "    #输出\n",
    "    out = tf.add(tf.matmul(fc1,weights['out']),biases['out'])\n",
    "    return out\n",
    "\n",
    "'''    #全连接层2\n",
    "    fc2 = tf.reshape(fc1, [-1,weights['wf2'].get_shape().as_list()[0]])\n",
    "    fc2 = tf.add(tf.matmul(fc2,weights['wf2']),biases['bf2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    #dropout\n",
    "    fc2 = tf.nn.dropout(fc2,dropout)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn_net(x,weights,biases,keep_prob)\n",
    "#loss func\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "#evaluate func\n",
    "correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_1, batch_y_1 = g_batches('data1_train.tfrecords',batch_size)\n",
    "batch_y_1 = tf.one_hot(batch_y_1,n_classes,1,0)\n",
    "\n",
    "valid_x_1, valid_y_1 = g_batches('data1_test.tfrecords',batch_size)\n",
    "valid_y_1 = tf.one_hot(valid_y_1,n_classes,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Session:\n",
      "\n",
      "Print training accuracy:\n",
      "epoch3000, Minibatch Loss = 8798.440430, Training Accuracy = 0.00667\n",
      "\n",
      "[24 62 26 64  3 42 42 26 53 10 34 31 56 19 35 60 14 18 55] \n",
      " [58 30 17 25 58 56 42 58 27 30  6 29 27 30 42 14 53 42 42]\n",
      "Print training accuracy:\n",
      "epoch6000, Minibatch Loss = 7321.375977, Training Accuracy = 0.01000\n",
      "\n",
      "[40 42  1  4 56  0 22  4  8 48 53  9 55 10  1 28 58 34 32] \n",
      " [30 60 30 42 60 61 29 30 45 27 28  8 43 42 30 52 58 42 25]\n",
      "Print training accuracy:\n",
      "epoch9000, Minibatch Loss = 6306.354004, Training Accuracy = 0.02333\n",
      "\n",
      "[54  1 63 11  4 40 30 21 57 12 14 11 17 50 25 25 58 47 24] \n",
      " [45 42 36 60 28 27 45 42 36 27 27  8 13 58 28 28 23 47 27]\n",
      "Print training accuracy:\n",
      "epoch12000, Minibatch Loss = 4975.745117, Training Accuracy = 0.02000\n",
      "\n",
      "[56 20 45 52 18 28 50 42 56 52 18 37 23 50 43 21 12 11 23] \n",
      " [43 58  1 53 29 23 32 25 60 40 30 11 42 39 42 58 39 36 27]\n",
      "Print training accuracy:\n",
      "epoch15000, Minibatch Loss = 4509.710449, Training Accuracy = 0.02000\n",
      "\n",
      "[52 20 24 26  4 27  6 13 31 28 30 36 42 58  6 22 10 43 48] \n",
      " [55  4  6 25 36 45 60 50 39 23 48 32  1 27  3  6 30 20 30]\n",
      "Print training accuracy:\n",
      "epoch18000, Minibatch Loss = 3853.083740, Training Accuracy = 0.02333\n",
      "\n",
      "[35  3 36 32 60 35 47 43 22 30 35 38 53 45 56 36 10 20 47] \n",
      " [56  3 62 33  4 62 15 63 55 10  4 15 46 30 17 63 25 55 59]\n",
      "Print training accuracy:\n",
      "epoch21000, Minibatch Loss = 3537.078857, Training Accuracy = 0.03667\n",
      "\n",
      "[13 31 20 33 14 62 15 45 14 37 27 59 20  8 18  9 45 44 47] \n",
      " [29 13 56 39  6 28  3 56 46 55  1 39 25 25 61 48 58 28 14]\n",
      "Print training accuracy:\n",
      "epoch24000, Minibatch Loss = 3079.755859, Training Accuracy = 0.03000\n",
      "\n",
      "[45 41 33 44 50 34 48 52 22 59 29 29 15 63 57 48 36 45 32] \n",
      " [36 36 35 14 31 48 58 10 39 53 46 63 14 32 17 43 25 60 64]\n",
      "Print training accuracy:\n",
      "epoch27000, Minibatch Loss = 2712.096680, Training Accuracy = 0.03333\n",
      "\n",
      "[25 28 63 23 57 43 46  8 17 52 14 19 54 53 58  9 41  0 55] \n",
      " [59  3 16 29 63  6  8 29  1 40  3 28  0 12 47 14 56 61  3]\n",
      "Print training accuracy:\n",
      "epoch30000, Minibatch Loss = 2695.078857, Training Accuracy = 0.02667\n",
      "\n",
      "[32 32 40 22 52  7 52 43 48 19 32 26  4  9 28  0 45 31 31] \n",
      " [50 64 63 19 40 14 25 43 16 39 50 28 39 10 22 11 50 61 15]\n",
      "Optimization Finished\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: #开始一个会话\n",
    "    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess = sess, coord = coord)\n",
    "\n",
    "    step = 1\n",
    "    print(\"Start Session:\\n\")\n",
    "    while step*batch_size < epoch:\n",
    "        #print(\"after g_batch\\n\")\n",
    "        x_, y_ = sess.run([batch_x_1,batch_y_1])\n",
    "        #print(\"after transform to array\\n\")\n",
    "        step += 1\n",
    "\n",
    "        sess.run(optimizer,feed_dict={x: x_, y: y_, keep_prob: dropout})\n",
    "        if not step%5:\n",
    "            print('Print training accuracy:')\n",
    "            loss_,acc_ = sess.run([loss,accuracy], feed_dict = {x: x_, y: y_, keep_prob: dropout})\n",
    "            print(\"epoch\" + str(step*batch_size) + \", Minibatch Loss = \" + \\\n",
    "                  \"{:.6f}\".format(loss_) + \", Training Accuracy = \" + \\\n",
    "                  \"{:.5f}\".format(acc_) + \"\\n\")\n",
    "            print(np.argmax(y_,1)[1:20],\"\\n\",np.argmax(sess.run(pred,feed_dict = {x : x_, y : y_, keep_prob : dropout})[1:20],1))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished\")\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument 52 has invalid type <class 'numpy.int32'>, must be a string or Tensor. (Can not convert a int32 into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 282\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3566\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[0;32m-> 3567\u001b[0;31m                                                            types_str))\n\u001b[0m\u001b[1;32m   3568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a int32 into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eca6ae1770cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/Optimus-Prime/Desktop/test_image/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlabel1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0myonehot1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel1_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1125\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    284\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    285\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument 52 has invalid type <class 'numpy.int32'>, must be a string or Tensor. (Can not convert a int32 into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: #开始一个会话\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    coord=tf.train.Coordinator()\n",
    "    threads= tf.train.start_queue_runners(coord=coord)\n",
    "    cwd = '/Users/Optimus-Prime/Desktop/test_image/'\n",
    "    label1_train = sess.run(label1_train)\n",
    "    yonehot1 = sess.run(tf.one_hot(label1_train,65,1,0))\n",
    "    print(label1_train)\n",
    "    print(yonehot1)\n",
    "    '''for i in range(1000):\n",
    "        example, l = sess.run([image1,label1])#在会话中取出image和label\n",
    "        \n",
    "        img=Image.fromarray(example, 'RGB')#这里Image是之前提到的\n",
    "        img.save(cwd+str(i)+'_''Label_'+str(l)+'.jpg')#存下图片\n",
    "        print(sess.run(image1),'end')'''\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
