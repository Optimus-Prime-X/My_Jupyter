{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Optimus-Prime/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(filename):\n",
    "    class_train = []\n",
    "    label_train = []\n",
    "    for train_class in os.listdir(filename):\n",
    "        if train_class != '.DS_Store':\n",
    "            for pic in os.listdir(filename+train_class):\n",
    "                class_train.append(filename+train_class+'/'+pic)\n",
    "                label_train.append(train_class)\n",
    "    temp = np.array([class_train,label_train])\n",
    "    temp = temp.transpose()\n",
    "    #shuffle the samples\n",
    "    np.random.shuffle(temp)\n",
    "    #after transpose, images is in dimension 0 and label in dimension 1\n",
    "    image_list = list(temp[:,0])\n",
    "    label_list = list(temp[:,1])\n",
    "    label_list = [int(i[5:]) for i in label_list]\n",
    "    #print(label_list)\n",
    "    return image_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(image,label,resize_w,resize_h,batch_size,capacity):\n",
    "    #convert the list of images and labels to tensor\n",
    "    image = tf.cast(image,tf.string)\n",
    "    label = tf.cast(label,tf.int64)\n",
    "    queue = tf.train.slice_input_producer([image,label])\n",
    "    label = queue[1]\n",
    "    image_c = tf.read_file(queue[0])\n",
    "    image = tf.image.decode_jpeg(image_c,channels = 3)\n",
    "    #resize\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image,resize_w,resize_h)\n",
    "    #(x - mean) / adjusted_stddev\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    image_batch,label_batch = tf.train.batch([image,label],\n",
    "                                             batch_size = batch_size,\n",
    "                                             num_threads = 64,\n",
    "                                             capacity = capacity)\n",
    "    images_batch = tf.cast(image_batch,tf.float32)\n",
    "    labels_batch = tf.reshape(label_batch,[batch_size])\n",
    "    return images_batch,labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev = 0.01))\n",
    "#init weights\n",
    "weights = {\n",
    "    \"w1\":init_weights([3,3,3,16]),\n",
    "    \"w2\":init_weights([3,3,16,128]),\n",
    "    \"w3\":init_weights([3,3,128,256]),\n",
    "    \"w4\":init_weights([4096,4096]),\n",
    "    \"wo\":init_weights([4096,2])\n",
    "    }\n",
    "\n",
    "#init biases\n",
    "biases = {\n",
    "    \"b1\":init_weights([16]),\n",
    "    \"b2\":init_weights([128]),\n",
    "    \"b3\":init_weights([256]),\n",
    "    \"b4\":init_weights([4096]),\n",
    "    \"bo\":init_weights([2])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,w,b):\n",
    "    x = tf.nn.conv2d(x,w,strides = [1,1,1,1],padding = \"SAME\")\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def pooling(x):\n",
    "    return tf.nn.max_pool(x,ksize = [1,2,2,1],strides = [1,2,2,1],padding = \"SAME\")\n",
    "\n",
    "def norm(x,lsize = 4):\n",
    "    return tf.nn.lrn(x,depth_radius = lsize,bias = 1,alpha = 0.001/9.0,beta = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmodel(images):\n",
    "    l1 = conv2d(images,weights[\"w1\"],biases[\"b1\"])\n",
    "    l2 = pooling(l1)\n",
    "    l2 = norm(l2)\n",
    "    l3 = conv2d(l2,weights[\"w2\"],biases[\"b2\"])\n",
    "    l4 = pooling(l3)\n",
    "    l4 = norm(l4)\n",
    "    l5 = conv2d(l4,weights[\"w3\"],biases[\"b3\"])\n",
    "    #same as the batch size\n",
    "    l6 = pooling(l5)\n",
    "    l6 = tf.reshape(l6,[-1,weights[\"w4\"].get_shape().as_list()[0]])\n",
    "    l7 = tf.nn.relu(tf.matmul(l6,weights[\"w4\"])+biases[\"b4\"])\n",
    "    soft_max = tf.add(tf.matmul(l7,weights[\"wo\"]),biases[\"bo\"])\n",
    "    return soft_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits,label_batches):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=label_batches)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(logits,labels):\n",
    "    acc = tf.nn.in_top_k(logits,labels,1)\n",
    "    acc = tf.cast(acc,tf.float32)\n",
    "    acc = tf.reduce_mean(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(loss,lr):\n",
    "    train_op = tf.train.RMSPropOptimizer(lr,0.9).minimize(loss)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    data_dir = '/Users/Optimus-Prime/Desktop/homework/dset1/train/'\n",
    "    image,label = get_files(data_dir)\n",
    "    image_batches,label_batches = get_batches(image,label,128,128,16,20)\n",
    "    p = model.mmodel(image_batches)\n",
    "    cost = model.loss(p,label_batches)\n",
    "    train_op = model.training(cost,0.001)\n",
    "    acc = model.get_accuracy(p,label_batches)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess = sess,coord = coord)\n",
    "    \n",
    "    try:\n",
    "       for step in np.arange(1000):\n",
    "           print(step)\n",
    "           if coord.should_stop():\n",
    "               break\n",
    "           _,train_acc,train_loss = sess.run([train_op,acc,cost])\n",
    "           print(\"loss:{} accuracy:{}\".format(train_loss,train_acc))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"Done!!!\")\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2f18cc448813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-d7ff1f204d07>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
