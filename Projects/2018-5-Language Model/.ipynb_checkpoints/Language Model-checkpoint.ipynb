{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 导入所需模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "38fa3aef-8df8-4a2e-8c5c-77776a048620"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Optimus-Prime/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 预处理语句"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e7c71236-91ca-4c3d-b969-77bd1bb8babe"
    }
   },
   "source": [
    "#### 读取文本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "edf0ec3b-f0a8-4fdd-a5be-881236ce1a5f"
    }
   },
   "outputs": [],
   "source": [
    "def _read_words(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return f.read().replace('\\n', '<eos>').split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "60455362-024a-47f5-a9b6-5a3325ca886c"
    }
   },
   "source": [
    "#### 分词成list并赋予id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "91594c79-7bec-4028-8efe-7821418b8d89"
    }
   },
   "outputs": [],
   "source": [
    "def _build_vocab(filename):\n",
    "    data = _read_words(filename)\n",
    "\n",
    "    counter = Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "    return words, word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a9700209-2a94-4d86-88e4-a8602af2974a"
    }
   },
   "source": [
    "#### 读取文件对应的id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "95a6055c-3dd8-42e3-ab1f-dcb32bf6df7a"
    }
   },
   "outputs": [],
   "source": [
    "def _file_to_word_ids(filename, word_to_id):\n",
    "    data = _read_words(filename)\n",
    "    return [word_to_id[x] for x in data if x in word_to_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f16d203d-004b-4175-91bb-d910601dbdd3"
    }
   },
   "source": [
    "#### 将id序列转化为句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "3e705393-cf91-45b9-9816-d7f7abf26490"
    }
   },
   "outputs": [],
   "source": [
    "def to_words(sentence, words):\n",
    "    return list(map(lambda x: words[x], sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成训练与验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "49d5944a-4e5e-4d1a-a5f2-81c30669bd6e"
    }
   },
   "outputs": [],
   "source": [
    "def _raw_data(data_path):\n",
    "    train_path = os.path.join(data_path, 'train.txt')\n",
    "    valid_path = os.path.join(data_path, 'valid.txt')\n",
    "    test_path = os.path.join(data_path, 'test.txt')\n",
    "\n",
    "    words, word_to_id = _build_vocab(train_path)\n",
    "    train_data = _file_to_word_ids(train_path, word_to_id)\n",
    "    valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
    "    test_data = _file_to_word_ids(test_path, word_to_id)\n",
    "\n",
    "    return train_data, valid_data, test_data, words, word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 产生训练batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "64a9d9ff-3c8e-44c5-a862-9e1ee27c1ed2"
    }
   },
   "outputs": [],
   "source": [
    "def _producer(raw_data, batch_size=64, num_steps=20, stride=1):\n",
    "    data_len = len(raw_data)\n",
    "\n",
    "    sentences = []\n",
    "    next_words = []\n",
    "    for i in range(0, data_len - num_steps, stride):\n",
    "        sentences.append(raw_data[i:(i + num_steps)])\n",
    "        next_words.append(raw_data[i + num_steps])\n",
    "\n",
    "    sentences = np.array(sentences)\n",
    "    next_words = np.array(next_words)\n",
    "\n",
    "    batch_len = len(sentences) // batch_size\n",
    "    x = np.reshape(sentences[:(batch_len * batch_size)], \\\n",
    "        [batch_len, batch_size, -1])\n",
    "\n",
    "    y = np.reshape(next_words[:(batch_len * batch_size)], \\\n",
    "        [batch_len, batch_size])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 观察x，y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "ff8792fa-2cb1-4537-ac27-7b8a9915872e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14524, 64, 20)\n",
      "(1152, 64)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, _, words, word_to_id = _raw_data('/Users/Optimus-Prime/Documents/My_Jupyter/Language Model')\n",
    "x_train, y_train = _producer(train_data)\n",
    "x_valid, y_valid = _producer(valid_data)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "517be641-908a-4e77-a97a-7964d03f7a70"
    }
   },
   "source": [
    "# 3 构建模型\n",
    "### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "25844da1-b9c6-409a-ad3c-e28c8da9a153"
    }
   },
   "outputs": [],
   "source": [
    "class LMConfig(object):\n",
    "    \"\"\"language model 配置项\"\"\"\n",
    "    batch_size = 64       # 每一批数据的大小\n",
    "    num_steps = 20        # 每一个句子的长度\n",
    "    stride = 3            # 取数据时的步长\n",
    "    vocab_size = 10000       # 词汇表大小\n",
    "\n",
    "    embedding_dim = 64    # 词向量维度\n",
    "    hidden_dim = 128      # RNN隐藏层维度\n",
    "    num_layers = 2        # RNN层数\n",
    "\n",
    "    learning_rate = 0.05  # 学习率\n",
    "    dropout = 0.8         # 每一层后的丢弃概率\n",
    "    rnn_model = 'gru'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Input(object):\n",
    "    \"\"\"按批次读取数据\"\"\"\n",
    "    def __init__(self, config, data):\n",
    "        self.batch_size = config.batch_size\n",
    "        self.num_steps = config.num_steps\n",
    "        self.vocab_size = config.vocab_size # 词汇表大小\n",
    "\n",
    "        self.input_data, self.targets = _producer(data,\n",
    "            self.batch_size, self.num_steps)\n",
    "\n",
    "        self.batch_len = self.input_data.shape[0] # 总批次\n",
    "        self.cur_batch = 0  # 当前批次\n",
    "\n",
    "    def next_batch(self):\n",
    "        \"\"\"读取下一批次\"\"\"\n",
    "        x = self.input_data[self.cur_batch]\n",
    "        y = self.targets[self.cur_batch]\n",
    "\n",
    "        # 转换为one-hot编码\n",
    "        y_ = np.zeros((y.shape[0], self.vocab_size), dtype=np.bool)\n",
    "        for i in range(y.shape[0]):\n",
    "            y_[i][y[i]] = 1\n",
    "\n",
    "        # 如果到最后一个批次，则回到最开头\n",
    "        self.cur_batch = (self.cur_batch +1) % self.batch_len\n",
    "\n",
    "        return x, y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型——LSTM+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, config, is_training=True):\n",
    "\n",
    "        self.num_steps = config.num_steps\n",
    "        self.vocab_size = config.vocab_size\n",
    "\n",
    "        self.embedding_dim = config.embedding_dim\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.num_layers = config.num_layers\n",
    "        self.rnn_model = config.rnn_model\n",
    "\n",
    "        self.learning_rate = config.learning_rate\n",
    "        #self.dropout = config.dropout\n",
    "        \n",
    "\n",
    "        self.placeholders()  # 输入占位符\n",
    "        self.rnn()           # rnn 模型构建\n",
    "        self.cost()          # 代价函数\n",
    "        self.optimize()      # 优化器\n",
    "        self.error()         # 错误率\n",
    "\n",
    "\n",
    "    def placeholders(self):\n",
    "        \"\"\"输入数据的占位符\"\"\"\n",
    "        self._inputs = tf.placeholder(tf.int32, [None, self.num_steps])\n",
    "        self._targets = tf.placeholder(tf.int32, [None, self.vocab_size])\n",
    "        self.dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "    def input_embedding(self):\n",
    "        \"\"\"将输入转换为词向量表示\"\"\"\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            embedding = tf.get_variable(\n",
    "                \"embedding\", [self.vocab_size,\n",
    "                    self.embedding_dim], dtype=tf.float32)\n",
    "            _inputs = tf.nn.embedding_lookup(embedding, self._inputs)\n",
    "\n",
    "        return _inputs\n",
    "\n",
    "\n",
    "    def rnn(self):\n",
    "        \"\"\"rnn模型构建\"\"\"\n",
    "        def lstm_cell():  # 基本的lstm cell\n",
    "            return tf.contrib.rnn.BasicLSTMCell(self.hidden_dim,\n",
    "                state_is_tuple=True)\n",
    "\n",
    "        def gru_cell():   # gru cell，速度更快\n",
    "            return tf.contrib.rnn.GRUCell(self.hidden_dim)\n",
    "\n",
    "        def dropout_cell():    # 在每个cell后添加dropout\n",
    "            if (self.rnn_model == 'lstm'):\n",
    "                cell = lstm_cell()\n",
    "            else:\n",
    "                cell = gru_cell()\n",
    "            return tf.contrib.rnn.DropoutWrapper(cell,\n",
    "                output_keep_prob=self.dropout)\n",
    "\n",
    "        cells = [dropout_cell() for _ in range(self.num_layers)]\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)  # 多层rnn\n",
    "\n",
    "        _inputs = self.input_embedding()\n",
    "        _outputs, _ = tf.nn.dynamic_rnn(cell=cell,\n",
    "            inputs=_inputs, dtype=tf.float32)\n",
    "\n",
    "        # _outputs的shape为 [batch_size, num_steps, hidden_dim]\n",
    "        last = _outputs[:, -1, :]  # 只需要最后一个输出\n",
    "\n",
    "        # dense 和 softmax 用于分类，以找出各词的概率\n",
    "        logits = tf.layers.dense(inputs=last, units=self.vocab_size)   \n",
    "        prediction = tf.nn.softmax(logits)  \n",
    "\n",
    "        self._logits = logits\n",
    "        self._pred = prediction\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"计算交叉熵代价函数\"\"\"\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=self._logits, labels=self._targets)\n",
    "        cost = tf.reduce_mean(cross_entropy)\n",
    "        self.cost = cost\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"使用adam优化器\"\"\"\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        self.optim = optimizer.minimize(self.cost)\n",
    "\n",
    "    def error(self):\n",
    "        \"\"\"计算错误率\"\"\"\n",
    "        mistakes = tf.not_equal(\n",
    "            tf.argmax(self._targets, 1), tf.argmax(self._pred, 1))\n",
    "        self.errors = tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练及验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(num_epochs=10):\n",
    "    config = LMConfig()   # 载入参数\n",
    "\n",
    "    # 载入源数据，这里只需要训练集\n",
    "    train_data, valid_data, _, words, word_to_id = _raw_data('/Users/Optimus-Prime/Documents/My_Jupyter/Language Model')\n",
    "    config.vocab_size = len(words)\n",
    "\n",
    "    # 数据分批\n",
    "    input_train = _Input(config, train_data)\n",
    "    input_valid = _Input(config, valid_data)\n",
    "    batch_len = input_train.batch_len\n",
    "\n",
    "    # 构建模型\n",
    "    model = Model(config)\n",
    "\n",
    "    # 创建session，初始化变量\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print('Start training...')\n",
    "    for epoch in range(num_epochs):  # 迭代轮次\n",
    "        for i in range(batch_len):   # 经过多少个batch\n",
    "            x_batch, y_batch = input_train.next_batch()\n",
    "            x_v_batch, y_v_batch = input_valid.next_batch()\n",
    "            # 取一个批次的数据，运行优化\n",
    "            feed_dict = {model._inputs: x_batch, model._targets: y_batch, model.dropout: config.dropout}\n",
    "            feed_dict_v = {model._inputs: x_v_batch, model._targets: y_v_batch, model.dropout: 1}\n",
    "            sess.run(model.optim, feed_dict=feed_dict)\n",
    "\n",
    "            # 每500个batch，输出一次中间结果\n",
    "            if i % 100 == 0:\n",
    "                cost,error = sess.run(model.cost, model.error, feed_dict=feed_dict)\n",
    "                msg = \"Epoch: {0:>3}, batch: {1:>6}, Loss: {2:>6.3}, error: {3:>6.3}\"\n",
    "                print(msg.format(epoch + 1, i + 1, cost, error))\n",
    "\n",
    "                # 输出验证集结果\n",
    "                total_error = 0\n",
    "                for j in range(20):\n",
    "                    error = sess.run(model.error, feed_dict=feed_dict_v)\n",
    "                    total_error += error/20\n",
    "                print('validation error: ',total_error)\n",
    "    print('Finish training...')\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Optimus-Prime/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-32-508d49562b2c>:76: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Start training...\n",
      "Epoch:   1, batch:      1, Loss:    9.1\n",
      "Predicted: <eos> chairman a is is years director years director once as <eos> british director <eos> british the N director <eos> <unk> and N old n.v. dutch british the N <eos> dutch dutch as <eos> group the <eos> <eos> nov. N dutch N nov. <unk> dutch <unk> N rifenburgh years N N <eos> gold N <eos> <eos> nov. director <eos> <eos> nov. as ssangyong the\n",
      "True: snack-food ssangyong swapo wachter <eos> pierre <unk> N years old will join the board as a nonexecutive director nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch publishing group <eos> rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate <eos> a form of asbestos once used to\n",
      "Epoch:   1, batch:    501, Loss:   6.84\n",
      "Predicted: the the the the the the the the the the the the the the the the the <unk> the the the the the the the the the the the the the the the the the the the the the the the the the the the N the the the the the the the the the the the the the the the the the the\n",
      "True: area so they went about it with a <unk> approach says richard <unk> a candela vice president <eos> indeed for many japanese trading companies the favorite u.s. small business is one whose research and development can be <unk> for future japanese use <eos> the japanese companies <unk> many small u.s. companies with promising products or ideas frequently putting their money behind projects that commercial\n",
      "Epoch:   1, batch:   1001, Loss:   7.01\n",
      "Predicted: N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N\n",
      "True: in a recent report moody 's said it expects intense competition to occur through the rest of the century in the securities industry which combined with overcapacity will create poor prospects for profitability <eos> it said that the temptation for <unk> to ease this profit pressure by taking greater risks is an additional rating factor <eos> both moody 's and s&p cited first boston\n",
      "Epoch:   1, batch:   1501, Loss:   6.24\n",
      "Predicted: N N N N N N N N N N N N N N N N N N N N N N N N N N N the N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N\n",
      "True: that for the week ended friday the balance of margin buying rose N billion yen $ N billion to N trillion yen $ N billion <eos> the balance of short positions outstanding fell N billion yen to N billion yen <eos> in london prices finished at intraday <unk> <unk> by a reassuring early performance on wall street and news that the british government will\n"
     ]
    }
   ],
   "source": [
    "run_epoch(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "70f700f1-2cf6-4761-836c-35f28935834e",
    "theme": {
     "70f700f1-2cf6-4761-836c-35f28935834e": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "70f700f1-2cf6-4761-836c-35f28935834e",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
