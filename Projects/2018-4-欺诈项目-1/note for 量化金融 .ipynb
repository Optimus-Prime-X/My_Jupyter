{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.linear_model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-41e9938964c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#from matplotlib.font_manager import FontProperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.linear_model"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.font_manager import FontProperties\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import copy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "dataset_path = \"/Users/Optimus-Prime/Desktop/cl_train_df.csv\"\n",
    "df = pd.read_csv(dataset_path) # read in data as the DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据处理部分---------------\n",
    "# 数据清洗\n",
    "#数据分割\n",
    "#IMbalanced 处理\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#特征选取--------------------------------------------------------------------\n",
    "ranked_feas = list(df.keys()) # get all feature names as a list object\n",
    "del ranked_feas[0] # delete 'category' column\n",
    "M_KS={}\n",
    "M_IV={}\n",
    "for ikey in ranked_feas:\n",
    "        files=df[['loan_status', ikey]]\n",
    "        length=len(files)-1\n",
    "        file=np.array(files)\n",
    "        D={}\n",
    "        sum=0.0\n",
    "        psum=0.0\n",
    "        nsum=0.0\n",
    "        for i in range(0,length):\n",
    "            [loan_status,score]=file[i]\n",
    "            if loan_status==\"loan_status\": continue           \n",
    "            try:\n",
    "                D[str(score)][2] +=1\n",
    "            except:\n",
    "                D[str(score)]=[0,0,1]\n",
    "            if loan_status==0:\n",
    "                D[str(score)][0] +=1\n",
    "                psum +=1\n",
    "            else:\n",
    "                D[str(score)][1] +=1\n",
    "                nsum +=1\n",
    "            sum +=1\n",
    "        num_bins=0            \n",
    "        dkeys=sorted(list(D.keys()),key=lambda x: x)\n",
    "        bin_sizes=[]\n",
    "        ksi=[]\n",
    "        iv=0.0\n",
    "        IIV=0.0\n",
    "        ipsum=0.0\n",
    "        insum=0.0\n",
    "        isum=0.0\n",
    "        iipsum=0.0\n",
    "        iinsum=0.0\n",
    "        for iscore in dkeys:\n",
    "            ipsum += D[iscore][0]\n",
    "            iipsum += D[iscore][0]\n",
    "            insum += D[iscore][1]\n",
    "            iinsum += D[iscore][1]\n",
    "            isum  += D[iscore][2]\n",
    "            t=isum/sum\n",
    "            if t>0.1 :\n",
    "                bin_sizes += [t]\n",
    "                num_bins += 1\n",
    "                ksi += [(np.abs(ipsum/psum-insum/nsum))*100]\n",
    "                iv += (iipsum/psum-iinsum/nsum)*(np.log((iipsum/psum+0.01)/(iinsum/nsum+0.01)))\n",
    "                isum=0.0\n",
    "                t=0.0\n",
    "                iipsum=0.0\n",
    "                iinsum=0.0\n",
    "            else:\n",
    "                continue\n",
    "        IIV=iv+(iipsum/psum-iinsum/nsum)*(np.log((iipsum/psum+0.01)/(iinsum/nsum+0.01)))\n",
    "        ksi += [(np.abs(ipsum/psum-insum/nsum))*100]\n",
    "        IKS=max(ksi)\n",
    "        M_KS[ikey]=IKS\n",
    "        M_IV[ikey]=IIV\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算排序并筛选变量\n",
    "        \n",
    "sorted_MKS=sorted(M_KS.items(),key=operator.itemgetter(1),reverse=True)\n",
    "sorted_MKS=[x for x in sorted_MKS if x[1]>0]\n",
    "sorted_MIV=sorted(M_IV.items(),key=operator.itemgetter(1),reverse=True)\n",
    "sorted_MIV=[x for x in sorted_MIV if x[1]>0]\n",
    "sorted_feas_MKS=[x[0] for x in sorted_MKS]\n",
    "sorted_feas_MIV=[x[0] for x in sorted_MIV]\n",
    "sorted_feas=[x for x in sorted_feas_MKS if x in sorted_feas_MIV]\n",
    "print (sorted_MKS)\n",
    "print (sorted_MIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型搭建----------------------------------------------------------------\n",
    "#以下进行数据逻辑回归\n",
    "\n",
    "#selected_df=pd.merge(df['loan_status'],(df[sorted_feas]),on='loan_status')\n",
    "\n",
    "dum_purpose=pd.get_dummies(selected_df['purpose'],prefix='purpose')\n",
    "cols_to_keep=ranked_feas.remove('purpose')\n",
    "#需要根据输入数据进行改变，确认或重写数据清理代码\n",
    "#dumed_data=df[cols_to_keep].join(dum_purpose.ix[:,'purpose_2':])\n",
    "\n",
    "#dumed_data['intercept']=1.0\n",
    "\n",
    "#逻辑回归执行\n",
    "#train_cols=dumed_data.columns[1:]\n",
    "#train_cols=selected_df.columns[1:]\n",
    "#logit=sm.Logit(dumed_data['loan_status'],dumed_data[train_cols])\n",
    "logit=sm.Logit(df['loan_status'],df[sorted_feas])\n",
    "logit_result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型测试部分---------------------------------------------------------------\n",
    "#数据的分割train和test，放在第一部分，此处临时使用\n",
    "#variable_train,variable_test,loan_states_train,loan_states_test=train_test_split(variable,loan_states,test_size=0.25,random_state=0)\n",
    "#loan_states,variable = dumed_data.ix[:,0],dumed_data.ix[:,1:]\n",
    "\n",
    "\n",
    "combos=copy.deepcopy(df)\n",
    "predict_cols = combos.columns[1:]  \n",
    "combos['intercept'] = 1.0 \n",
    "combos['predict'] = logit_result.predict(combos[predict_cols])\n",
    "total = 0.0  \n",
    "hit = 0.0  \n",
    "for value in combos.values:  \n",
    "    predict = value[-1]  \n",
    "  # 实际录取结果  \n",
    "    admit = int(value[0])  \n",
    "   \n",
    "  # 假定预测概率大于0.5则表示预测被录取  \n",
    "    if predict > 0.5:  \n",
    "        total += 1  \n",
    "    # 表示预测命中  \n",
    "    if admit == 1:  \n",
    "        hit += 1  \n",
    "  # 预测分数 predict, 是数据中的最后一列  \n",
    "  \n",
    "print 'Total: %d, Hit: %d, Precision: %.2f' % (total, hit, 100.0*hit/total) \n",
    "\n",
    "#RF模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
