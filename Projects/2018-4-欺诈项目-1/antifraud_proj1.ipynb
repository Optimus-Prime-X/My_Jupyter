{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project1 量化金融信用评估实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/Optimus-Prime/Documents/我的文件/课程相关/量化金融信用与风控分析/950503878_6_量化金融信用与反欺诈项目/LoanStats3d_securev1.csv', low_memory=False) # please note that this is a large file, it may take a little bit longer to read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset = \"antifraud_proj1_test.csv\"\n",
    "#test_df = pd.read_csv(dir_prefix + test_dataset, low_memory=False)\n",
    "#print 'Shape of test_df:', test_df.shape\n",
    "#print 'Which fields are missing in the test dataset?'\n",
    "#print set(sample_df.columns) - set(test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对Train_df数据进行清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['term'] = train_df['term'].replace([' 60 months',' 36 months'],[1,0])#'term' 修改为0-1变量\n",
    "train_df = train_df.drop(['id','member_id','issue_d','emp_title'], axis = 1)#删除id，member_id\n",
    "train_df['emp_length']=train_df['emp_length'].replace(['1 year', '10+ years', '2 years', '3 years', '4 years',\n",
    "                                 '5 years', '6 years', '7 years', '8 years', '9 years', \n",
    "                                 '< 1 year', 'n/a'],[1,10,2,3,4,5,6,7,8,9,0,0])\n",
    "train_df['home_ownership'] = train_df['home_ownership'].replace(['MORTGAGE', 'RENT', 'OWN','ANY'],[0,0.5,1,0.5])\n",
    "train_df['verification_status'] = train_df['verification_status'].replace(['Source Verified', \n",
    "                                                                             'Not Verified', 'Verified'],\n",
    "                                                                           [0.5,0,1])\n",
    "#修改各个字段为数字\n",
    "\n",
    "train_df = train_df[(train_df['loan_status']=='Current') | (train_df['loan_status']=='Charged Off') | (train_df['loan_status']=='Fully Paid')]\n",
    "train_df['loan_status'] = train_df['loan_status'].replace(['Current','Fully Paid','Charged Off',],[0,0,1])\n",
    "train_df.index = range(len(train_df))\n",
    "#修改因变量为数字\n",
    "\n",
    "del train_df['pymnt_plan']#数据值只有“n”，故删除\n",
    "del train_df['desc']#描述\n",
    "train_df['purpose'] = train_df['purpose'].replace(['car','credit_card','debt_consolidation','educational',\n",
    "                                                     'home_improvement','house','major_purchase','medical',\n",
    "                                                     'moving','other','renewable_energy','small_business',\n",
    "                                                     'vacation','wedding'],[0.6,0.2,1.0,0.2,0.4,0.4,0.6,0.6,0.4,0.2,0.6,0.8,0.2,0.4])\n",
    "del train_df['title']#和‘purpose’字段一致\n",
    "del train_df['zip_code']#借贷程序的zip code 前三位\n",
    "\n",
    "#根据贷款各项金额大小按比例排序\n",
    "\n",
    "#地区,我按照各地的人均GDP与总GDP，按照7:3的比例进行合计评分，并归一化\n",
    "train_df['addr_state'] = train_df['addr_state'].replace(['DC', 'TX', 'PA', 'GA', 'FL', 'NY', 'CA', 'TN', 'KS', 'MA', \n",
    "                                                           'RI','OH', 'OR', 'HI', 'SC', 'MD', 'AZ', 'WI', 'VA', 'CO', \n",
    "                                                           'IN', 'LA','NC', 'NJ', 'MO', 'NM', 'IL', 'MI', 'SD', 'WA', \n",
    "                                                           'NH', 'VT', 'AL','MN', 'CT', 'DE', 'NE', 'WV', 'MT', 'NV',\n",
    "                                                           'OK', 'WY', 'AR', 'KY','MS', 'ME', 'UT', 'ND', 'AK'],\n",
    "                                                          [0.249494545,0.065555092,0.039895621,0.085444756,0.593361556,\n",
    "                                                              0.190277765,0.278189313,1,0.227317672,0.192702231,0.155311576,\n",
    "                                                              0.131447429,0.280336943,0.132540357,0.106452086,0.069307246,\n",
    "                                                              0.15253082,0.302445071,0.21218416,0.030257468,0.137946485,\n",
    "                                                              0.208228197,0.110989561,0,0.048207504,0.16335986,0.231921874,\n",
    "                                                              0.161796013,0.117910048,0.2777898,0.050846682,0.094623649,\n",
    "                                                              0.494175602,0.191919255,0.085791932,0.160341405,0.220064923,\n",
    "                                                              0.111679786,0.046895947,0.10685987,0.109896491,0.441591068,\n",
    "                                                              0.097945954,0.207944043,0.06716049,0.242232775,0.141853116,\n",
    "                                                              0.013158262,0.213121431])\n",
    "#sample_df['addr_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenth = len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "year,month = [0]*lenth,[0]*lenth\n",
    "for i in range(lenth):\n",
    "    date = train_df['earliest_cr_line'][i].split('/')\n",
    "    year[i] = float(date[0])\n",
    "    month[i] = float(date[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_keys = list(train_df.keys())\n",
    "ear_num = 0\n",
    "for i in range(len(train_df_keys)):\n",
    "    if train_df_keys[i] == 'earliest_cr_line':\n",
    "        ear_num = i\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['earliest_cr_line']\n",
    "train_df.insert(18,'earliest_cr_line',pd.DataFrame([(2018-year[i])*12+12-month[i] for i in range(lenth)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>405055.000000</td>\n",
       "      <td>208129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.067894</td>\n",
       "      <td>34.076976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.251565</td>\n",
       "      <td>21.992834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loan_status  mths_since_last_delinq\n",
       "count  405055.000000           208129.000000\n",
       "mean        0.067894               34.076976\n",
       "std         0.251565               21.992834\n",
       "min         0.000000                0.000000\n",
       "25%         0.000000               15.000000\n",
       "50%         0.000000               31.000000\n",
       "75%         0.000000               50.000000\n",
       "max         1.000000              176.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['loan_status','mths_since_last_delinq']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上一次逾期距今的月数，nan代表没有逾期,取0，那么月份越高说明危险度越低，取月份数的倒数\n",
    "#train_df['mths_since_last_delinq'].unique()\n",
    "train_df['mths_since_last_delinq']=train_df['mths_since_last_delinq'].fillna(0)\n",
    "#sample_df['mths_since_last_delinq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上一次有记录的月份数\n",
    "train_df['mths_since_last_record'] = train_df['mths_since_last_record'].fillna(0)\n",
    "#sample_df['mths_since_last_record'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['revol_util'] = train_df['revol_util'].str.strip('%').astype(float)/100\n",
    "#网上将百分比转化的方法：p_float = df['p_str'].str.strip(\"%\").astype(float)/100\n",
    "#sample_df['revol_util'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['mths_since_recent_bc_dlq'] = train_df['mths_since_recent_bc_dlq'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['mths_since_recent_revol_delinq'] = train_df['mths_since_recent_revol_delinq'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_loan_status = train_df.loan_status\n",
    "train_df = train_df.drop('loan_status',axis = 1)\n",
    "train_df.insert(0,'loan_status',train_df_loan_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初步清洗完的数据集已导出到“clear_train_df.csv”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('clear_train_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据清理后的数据，进行归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train_df = pd.read_csv('./clear_train_df.csv')\n",
    "\n",
    "#del cl_train_df['Unnamed: 0']\n",
    "\n",
    "#cl_train_df = cl_train_df.drop([i for i in cl_train_keys if cl_train_df[i].count()<100000 ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_train_keys = list(cl_train_df.keys())\n",
    "num_non = [[i,len(cl_train_df)-cl_train_df[i].count()] for i in cl_train_keys]\n",
    "\n",
    "#cl_train_df['num_tl_120dpd_2m'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['revol_util', 156],\n",
       " ['open_acc_6m', 384509],\n",
       " ['open_il_6m', 384509],\n",
       " ['open_il_12m', 384509],\n",
       " ['open_il_24m', 384509],\n",
       " ['mths_since_rcnt_il', 385052],\n",
       " ['total_bal_il', 384509],\n",
       " ['il_util', 387175],\n",
       " ['open_rv_12m', 384509],\n",
       " ['open_rv_24m', 384509],\n",
       " ['max_bal_bc', 384509],\n",
       " ['all_util', 384509],\n",
       " ['inq_fi', 384509],\n",
       " ['total_cu_tl', 384509],\n",
       " ['inq_last_12m', 384509],\n",
       " ['bc_open_to_buy', 3765],\n",
       " ['bc_util', 4013],\n",
       " ['mo_sin_old_il_acct', 11837],\n",
       " ['mths_since_recent_bc', 3614],\n",
       " ['mths_since_recent_inq', 43442],\n",
       " ['num_rev_accts', 1],\n",
       " ['num_tl_120dpd_2m', 18365],\n",
       " ['percent_bc_gt_75', 4029]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[num_non[i] for i in range(len(num_non)) if num_non[i][1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_non = [i for i in num_non if i[1]>0]\n",
    "\n",
    "name_non = [num_non[i][0] for i in range(len(num_non))]\n",
    "\n",
    "for i in name_non:\n",
    "    cl_train_df[i].fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train_df.to_csv('cl_train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revol_util</th>\n",
       "      <th>bc_open_to_buy</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <th>mths_since_recent_bc</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>num_rev_accts</th>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404899.000000</td>\n",
       "      <td>401290.000000</td>\n",
       "      <td>401042.000000</td>\n",
       "      <td>393218.000000</td>\n",
       "      <td>401441.000000</td>\n",
       "      <td>361613.000000</td>\n",
       "      <td>405054.000000</td>\n",
       "      <td>386690.000000</td>\n",
       "      <td>401026.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.537100</td>\n",
       "      <td>9759.249540</td>\n",
       "      <td>62.056067</td>\n",
       "      <td>127.656211</td>\n",
       "      <td>24.989134</td>\n",
       "      <td>6.782118</td>\n",
       "      <td>14.890773</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>47.279265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.238924</td>\n",
       "      <td>14911.049474</td>\n",
       "      <td>27.580544</td>\n",
       "      <td>52.005753</td>\n",
       "      <td>32.386066</td>\n",
       "      <td>5.924437</td>\n",
       "      <td>8.293047</td>\n",
       "      <td>0.030033</td>\n",
       "      <td>36.042640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.359000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>41.300000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>4436.500000</td>\n",
       "      <td>65.600000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>11750.000000</td>\n",
       "      <td>86.300000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.930000</td>\n",
       "      <td>559912.000000</td>\n",
       "      <td>318.200000</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          revol_util  bc_open_to_buy        bc_util  mo_sin_old_il_acct  \\\n",
       "count  404899.000000   401290.000000  401042.000000       393218.000000   \n",
       "mean        0.537100     9759.249540      62.056067          127.656211   \n",
       "std         0.238924    14911.049474      27.580544           52.005753   \n",
       "min         0.000000        0.000000       0.000000            0.000000   \n",
       "25%         0.359000     1372.000000      41.300000          101.000000   \n",
       "50%         0.540000     4436.500000      65.600000          130.000000   \n",
       "75%         0.720000    11750.000000      86.300000          153.000000   \n",
       "max         1.930000   559912.000000     318.200000          724.000000   \n",
       "\n",
       "       mths_since_recent_bc  mths_since_recent_inq  num_rev_accts  \\\n",
       "count         401441.000000          361613.000000  405054.000000   \n",
       "mean              24.989134               6.782118      14.890773   \n",
       "std               32.386066               5.924437       8.293047   \n",
       "min                0.000000               0.000000       2.000000   \n",
       "25%                6.000000               2.000000       9.000000   \n",
       "50%               14.000000               5.000000      13.000000   \n",
       "75%               30.000000              10.000000      19.000000   \n",
       "max              615.000000              25.000000     118.000000   \n",
       "\n",
       "       num_tl_120dpd_2m  percent_bc_gt_75  \n",
       "count     386690.000000     401026.000000  \n",
       "mean           0.000753         47.279265  \n",
       "std            0.030033         36.042640  \n",
       "min            0.000000          0.000000  \n",
       "25%            0.000000         14.300000  \n",
       "50%            0.000000         50.000000  \n",
       "75%            0.000000         75.000000  \n",
       "max            6.000000        100.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_train_df[[i[0] for i in num_non if (i[1]>0)&(i[1]<100000)]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用箱形图计算各个特征的离群点数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27500, 0, 0, 0, 0, 18401, 0, 0, 34800, 61, 83168, 11786, 11275, 11275, 16076, 1907, 71270, 10356, 71275, 24191, 35, 9151, 2292, 63658, 14600, 12563, 18307, 10090, 15214, 19990, 18361, 17747, 13709, 17760, 20156, 20523, 23987, 9523, 9507, 15344, 8934, 22234, 35859, 22, 3805, 1729, 26526, 10491, 33688, 26546, 5132, 38892, 92639, 8624, 39352, 98584, 9678, 13849, 19740, 8897, 25243, 8860, 11258, 12570, 10148, 273, 1539, 24201, 10821, 24760, 0, 48795, 15825, 14158, 23339, 24524, 20254]\n"
     ]
    }
   ],
   "source": [
    "cl_train_keys = list(cl_train_df.keys())\n",
    "#del cl_train_df['Unnamed: 0']\n",
    "num_abnormal = [0]*len(cl_train_keys)\n",
    "lenth = len(train_df)\n",
    "for i in range(len(cl_train_keys)):\n",
    "    Qu = cl_train_df[cl_train_keys[i]].describe()['75%']\n",
    "    Ql = cl_train_df[cl_train_keys[i]].describe()['25%']\n",
    "    IQR = Qu - Ql\n",
    "    L = np.sort(cl_train_df[cl_train_keys[i]])\n",
    "    j = 0\n",
    "    while((L[j]<Ql-1.5*IQR) or L[lenth-1-j]>Qu+1.5*IQR):\n",
    "        j += 1\n",
    "        if L[j]<Ql-1.5*IQR:\n",
    "            num_abnormal[i] += 1\n",
    "        if L[lenth-1-j]>Qu+1.5*IQR:\n",
    "            num_abnormal[i] += 1\n",
    "print num_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(num_abnormal).to_csv('num_abnormal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查之后，选取需要进行异常值处理的字段，形成abnormal_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abnormal_keys = ['dti','revol_util','bc_util','mo_sin_old_il_acct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train_df[abnormal_keys].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lenth):\n",
    "    cl_train_df.loc[i,'dti'] = abs(cl_train_df['dti'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "for i in range(4):\n",
    "    Qu = cl_train_df[abnormal_keys[i]].describe()['75%']\n",
    "    Ql = cl_train_df[abnormal_keys[i]].describe()['25%']\n",
    "    mean = cl_train_df[abnormal_keys[i]].describe()['mean']\n",
    "    std = cl_train_df[abnormal_keys[i]].describe()['std']\n",
    "    IQR = Qu - Ql\n",
    "    cl_train_df = cl_train_df.sort_values(by = abnormal_keys[i])\n",
    "    cl_train_df.index = range(lenth)\n",
    "    j = 0\n",
    "    while((cl_train_df[abnormal_keys[i]][j]<Ql-1.5*IQR) or cl_train_df[abnormal_keys[i]][lenth-1-j]>Qu+1.5*IQR):\n",
    "        if cl_train_df[abnormal_keys[i]][j]<Ql-1.5*IQR:\n",
    "            cl_train_df.loc[j,abnormal_keys[i]] = abs(float(np.random.normal(mean,std,1)))\n",
    "        if cl_train_df[abnormal_keys[i]][lenth-1-j]>Qu+1.5*IQR:\n",
    "            cl_train_df.loc[lenth-1-j,abnormal_keys[i]]  = abs(float(np.random.normal(mean,std,1)))\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_abnormal = [0]*4\n",
    "for i in range(4):\n",
    "    Qu = cl_train_df[abnormal_keys[i]].describe()['75%']\n",
    "    Ql = cl_train_df[abnormal_keys[i]].describe()['25%']\n",
    "    mean = cl_train_df[abnormal_keys[i]].describe()['mean']\n",
    "    std = cl_train_df[abnormal_keys[i]].describe()['std']\n",
    "    IQR = Qu - Ql\n",
    "    cl_train_df = cl_train_df.sort_values(by = abnormal_keys[i])\n",
    "    cl_train_df.index = range(lenth)\n",
    "    j = 0\n",
    "    while((cl_train_df[abnormal_keys[i]][j]<Ql-1.5*IQR) or cl_train_df[abnormal_keys[i]][lenth-1-j]>Qu+1.5*IQR):\n",
    "        j += 1\n",
    "        if cl_train_df[abnormal_keys[i]][j]<Ql-1.5*IQR:\n",
    "            num_abnormal[i] += 1\n",
    "        if cl_train_df[abnormal_keys[i]][lenth-1-j]>Qu+1.5*IQR:\n",
    "            num_abnormal[i] += 1\n",
    "num_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    405055.000000\n",
       "mean         19.137358\n",
       "std          23.899037\n",
       "min           0.000000\n",
       "25%          12.540000\n",
       "50%          18.520000\n",
       "75%          25.260000\n",
       "max        9999.000000\n",
       "Name: dti, dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_train_df[abnormal_keys[0]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.724175884266502"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(np.random.normal(0,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34801"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([cl_train_df['dti'][i] for i in range(lenth) if cl_train_df['addr_state'][i]>0.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    405055.000000\n",
       "mean      15213.303193\n",
       "std        8571.239185\n",
       "min        1000.000000\n",
       "25%        8500.000000\n",
       "50%       14000.000000\n",
       "75%       20000.000000\n",
       "max       35000.000000\n",
       "Name: loan_amnt, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_train_df['loan_amnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_status', 'loan_amnt', 'term', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'purpose', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit']\n"
     ]
    }
   ],
   "source": [
    "print cl_train_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in cl_train_keys:\n",
    "    QU = np.percentile(cl_train_df[i],75)\n",
    "    QL = np.percentile(cl_train_df[i],25)\n",
    "    IQR = QU - QL\n",
    "    num_abnormal.append([i,len([cl_train_df[i][j] for j in range(len(cl_train_df)) \n",
    "                                if (cl_train_df[i][j]<(QL-1.5*IQR))|(cl_train_df[i][j]>(QU+1.5*IQR))])])\n",
    "num_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the results\n",
    "You do not need to modify the following lines. \n",
    "\n",
    "**Please do not modify the file name \"antifraud_proj1_result.csv\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Predict': np.zeros(test_df.shape[0])}\n",
    "test_predict = pd.DataFrame(data=d)\n",
    "test_predict.to_csv(\"antifraud_proj1_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
